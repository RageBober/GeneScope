#!/usr/bin/env python3
"""–î–µ–º–æ–Ω—Å—Ç—Ä–∞—Ü–∏—è –ø–∞—Ä–∞–ª–ª–µ–ª—å–Ω–æ–π –æ–±—Ä–∞–±–æ—Ç–∫–∏ BioForge —Å –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω—ã–º–∏ —Ç–µ—Å—Ç–∞–º–∏."""

import pandas as pd
import numpy as np
from pathlib import Path
import time
import sys
import argparse

# –î–æ–±–∞–≤–ª—è–µ–º src –≤ –ø—É—Ç—å –¥–ª—è –∏–º–ø–æ—Ä—Ç–∞
sys.path.insert(0, str(Path(__file__).parent / "src"))

def create_test_genomic_data(size_mb: int = 150, file_type: str = "csv") -> Path:
    """–°–æ–∑–¥–∞–µ—Ç —Ç–µ—Å—Ç–æ–≤—ã–µ –≥–µ–Ω–æ–º–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ –∑–∞–¥–∞–Ω–Ω–æ–≥–æ —Ä–∞–∑–º–µ—Ä–∞.
    
    Args:
        size_mb: –†–∞–∑–º–µ—Ä —Ñ–∞–π–ª–∞ –≤ –ú–ë
        file_type: –¢–∏–ø —Ñ–∞–π–ª–∞ (csv –∏–ª–∏ vcf)
        
    Returns:
        –ü—É—Ç—å –∫ —Å–æ–∑–¥–∞–Ω–Ω–æ–º—É —Ñ–∞–π–ª—É
    """
    print(f"üìä –°–æ–∑–¥–∞–Ω–∏–µ —Ç–µ—Å—Ç–æ–≤—ã—Ö –¥–∞–Ω–Ω—ã—Ö {size_mb}MB ({file_type.upper()})...")
    
    # –û—Ü–µ–Ω–∫–∞ –∫–æ–ª–∏—á–µ—Å—Ç–≤–∞ —Å—Ç—Ä–æ–∫ (–ø—Ä–∏–º–µ—Ä–Ω–æ 100 –±–∞–π—Ç –Ω–∞ —Å—Ç—Ä–æ–∫—É)
    rows_needed = int((size_mb * 1024 * 1024) / 100)
    
    if file_type.lower() == "vcf":
        # VCF –¥–∞–Ω–Ω—ã–µ (–≥–µ–Ω–æ–º–Ω—ã–µ –≤–∞—Ä–∏–∞–Ω—Ç—ã)
        data = {
            'CHROM': np.random.choice(['1', '2', '3', '4', '5', '6', '7', '8', '9', '10', 'X', 'Y'], rows_needed),
            'POS': np.random.randint(1000000, 250000000, rows_needed),
            'ID': [f'rs{i}' for i in range(rows_needed)],
            'REF': np.random.choice(['A', 'T', 'G', 'C'], rows_needed),
            'ALT': np.random.choice(['A', 'T', 'G', 'C'], rows_needed),
            'QUAL': np.random.uniform(10, 100, rows_needed),
            'FILTER': np.random.choice(['PASS', 'LowQual', 'PASS', 'PASS'], rows_needed),
            'INFO': [f'DP={dp};AF={af:.3f}' for dp, af in zip(
                np.random.randint(10, 200, rows_needed),
                np.random.uniform(0.01, 0.99, rows_needed)
            )],
            'FORMAT': ['GT:DP:GQ'] * rows_needed,
            'SAMPLE1': [f'{gt}:{dp}:{gq}' for gt, dp, gq in zip(
                np.random.choice(['0/0', '0/1', '1/1'], rows_needed),
                np.random.randint(10, 200, rows_needed),
                np.random.randint(20, 99, rows_needed)
            )]
        }
        test_file = Path(f"test_genomic_data_{size_mb}mb.vcf")
        df = pd.DataFrame(data)
        df.to_csv(test_file, sep='\t', index=False)
        
    else:  # CSV
        # CSV –¥–∞–Ω–Ω—ã–µ (–æ–±—â–∏–µ –±–∏–æ–ª–æ–≥–∏—á–µ—Å–∫–∏–µ –¥–∞–Ω–Ω—ã–µ)
        data = {
            'SampleID': [f'Sample_{i:06d}' for i in range(rows_needed)],
            'Gene': np.random.choice([f'Gene_{i}' for i in range(1, 1001)], rows_needed),
            'Expression': np.random.lognormal(3, 1, rows_needed),
            'Chromosome': np.random.choice([f'chr{i}' for i in range(1, 23)] + ['chrX', 'chrY'], rows_needed),
            'Position': np.random.randint(1000000, 250000000, rows_needed),
            'QualityScore': np.random.uniform(0, 100, rows_needed),
            'Coverage': np.random.randint(1, 1000, rows_needed),
            'Strand': np.random.choice(['+', '-'], rows_needed),
            'Treatment': np.random.choice(['Control', 'Treated'], rows_needed),
            'BatchEffect': np.random.normal(1, 0.1, rows_needed)
        }
        test_file = Path(f"test_genomic_data_{size_mb}mb.csv")
        df = pd.DataFrame(data)
        df.to_csv(test_file, index=False)
    
    actual_size = test_file.stat().st_size / 1024 / 1024
    print(f"‚úÖ –°–æ–∑–¥–∞–Ω —Ñ–∞–π–ª: {test_file} ({actual_size:.1f}MB, {len(df)} —Å—Ç—Ä–æ–∫)")
    return test_file


def benchmark_sequential_processing(test_file: Path, file_type: str):
    """–¢–µ—Å—Ç–∏—Ä—É–µ—Ç –ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω—É—é –æ–±—Ä–∞–±–æ—Ç–∫—É."""
    print(f"\nüìä –ü–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–∞—è –æ–±—Ä–∞–±–æ—Ç–∫–∞ ({file_type.upper()}):")
    print("-" * 50)
    
    try:
        from genoscope.main import GenoScopeProcessor
        
        processor = GenoScopeProcessor()
        
        start_time = time.time()
        success = processor.load_file(str(test_file), file_type)
        load_time = time.time() - start_time
        
        if success and processor.data is not None:
            records_count = len(processor.data)
            speed = records_count / load_time if load_time > 0 else 0
            
            print(f"‚è±Ô∏è  –í—Ä–µ–º—è –∑–∞–≥—Ä—É–∑–∫–∏: {load_time:.2f} —Å–µ–∫—É–Ω–¥")
            print(f"üìä –ó–∞–≥—Ä—É–∂–µ–Ω–æ –∑–∞–ø–∏—Å–µ–π: {records_count:,}")
            print(f"‚ö° –°–∫–æ—Ä–æ—Å—Ç—å: {speed:.0f} –∑–∞–ø–∏—Å–µ–π/—Å–µ–∫")
            
            # –¢–µ—Å—Ç–∏—Ä—É–µ–º –æ—á–∏—Å—Ç–∫—É –¥–∞–Ω–Ω—ã—Ö
            start_time = time.time()
            clean_success = processor.clean_data()
            clean_time = time.time() - start_time
            
            if clean_success:
                print(f"üßπ –û—á–∏—Å—Ç–∫–∞ –¥–∞–Ω–Ω—ã—Ö: {clean_time:.2f} —Å–µ–∫—É–Ω–¥")
            
            return {
                'success': True,
                'load_time': load_time,
                'clean_time': clean_time,
                'total_time': load_time + clean_time,
                'records': records_count,
                'speed': speed
            }
        else:
            print("‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ –∑–∞–≥—Ä—É–∑–∫–µ –¥–∞–Ω–Ω—ã—Ö")
            return {'success': False}
            
    except Exception as e:
        print(f"‚ùå –û—à–∏–±–∫–∞ –ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–æ–π –æ–±—Ä–∞–±–æ—Ç–∫–∏: {e}")
        return {'success': False, 'error': str(e)}


def benchmark_parallel_processing(test_file: Path, file_type: str, workers: int = 8):
    """–¢–µ—Å—Ç–∏—Ä—É–µ—Ç –ø–∞—Ä–∞–ª–ª–µ–ª—å–Ω—É—é –æ–±—Ä–∞–±–æ—Ç–∫—É."""
    print(f"\n‚ö° –ü–∞—Ä–∞–ª–ª–µ–ª—å–Ω–∞—è –æ–±—Ä–∞–±–æ—Ç–∫–∞ ({file_type.upper()}, {workers} –≤–æ—Ä–∫–µ—Ä–æ–≤):")
    print("-" * 50)
    
    try:
        from genoscope.parallel import DaskGenomicProcessor
        
        processor = DaskGenomicProcessor(
            n_workers=workers,
            memory_limit="2GB",
            threads_per_worker=2
        )
        
        if not processor.is_distributed:
            print("‚ö†Ô∏è  Dask –∫–ª–∞—Å—Ç–µ—Ä –Ω–µ–¥–æ—Å—Ç—É–ø–µ–Ω, –∏—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è fallback —Ä–µ–∂–∏–º")
        else:
            print(f"üéØ Dask dashboard: {processor.client.dashboard_link}")
        
        start_time = time.time()
        
        # –ó–∞–ø—É—Å–∫–∞–µ–º –ø–∞—Ä–∞–ª–ª–µ–ª—å–Ω—É—é –æ–±—Ä–∞–±–æ—Ç–∫—É
        results = processor.process_large_file_parallel(
            file_path=test_file,
            file_type=file_type,
            analysis_type="comprehensive",
            chunk_size_mb=50
        )
        
        total_time = time.time() - start_time
        
        if 'error' not in results:
            perf_summary = results.get('performance_summary', {})
            total_records = perf_summary.get('total_records_processed', 0)
            processing_speed = perf_summary.get('average_processing_speed', 0)
            
            print(f"‚è±Ô∏è  –û–±—â–µ–µ –≤—Ä–µ–º—è: {total_time:.2f} —Å–µ–∫—É–Ω–¥")
            print(f"üìä –û–±—Ä–∞–±–æ—Ç–∞–Ω–æ –∑–∞–ø–∏—Å–µ–π: {total_records:,}")
            print(f"‚ö° –°—Ä–µ–¥–Ω—è—è —Å–∫–æ—Ä–æ—Å—Ç—å: {processing_speed:.0f} –∑–∞–ø–∏—Å–µ–π/—Å–µ–∫")
            print(f"üîß –£—Å–ø–µ—à–Ω—ã–µ —á–∞–Ω–∫–∏: {results.get('successful_chunks', 0)}/{results.get('total_chunks', 0)}")
            
            # –î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã–µ –º–µ—Ç—Ä–∏–∫–∏
            if 'performance' in results:
                perf = results['performance']
                print(f"üìà Efficiency score: {perf.get('efficiency_score', 0):.1f}/100")
                print(f"üíæ –ü–∏–∫–æ–≤–∞—è –ø–∞–º—è—Ç—å: {perf.get('peak_memory_mb', 0):.1f}MB")
                print(f"üñ•Ô∏è  –°—Ä–µ–¥–Ω–µ–µ CPU: {perf.get('avg_cpu_percent', 0):.1f}%")
            
            processor.close()
            return {
                'success': True,
                'total_time': total_time,
                'records': total_records,
                'speed': processing_speed,
                'chunks': results.get('total_chunks', 0),
                'results': results
            }
        else:
            print(f"‚ùå –û—à–∏–±–∫–∞ –ø–∞—Ä–∞–ª–ª–µ–ª—å–Ω–æ–π –æ–±—Ä–∞–±–æ—Ç–∫–∏: {results['error']}")
            processor.close()
            return {'success': False, 'error': results['error']}
            
    except Exception as e:
        print(f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏–∏ –ø–∞—Ä–∞–ª–ª–µ–ª—å–Ω–æ–π –æ–±—Ä–∞–±–æ—Ç–∫–∏: {e}")
        return {'success': False, 'error': str(e)}


def benchmark_chunk_managers(test_file: Path, file_type: str):
    """–¢–µ—Å—Ç–∏—Ä—É–µ—Ç —Ä–∞–±–æ—Ç—É chunk managers."""
    print(f"\nüîß –¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ Chunk Managers ({file_type.upper()}):")
    print("-" * 50)
    
    try:
        from genoscope.parallel import get_chunk_manager
        
        chunk_manager = get_chunk_manager(file_type)
        print(f"üì¶ –ò—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è –º–µ–Ω–µ–¥–∂–µ—Ä: {chunk_manager.__class__.__name__}")
        
        start_time = time.time()
        chunks = chunk_manager.create_chunks(test_file, chunk_size_mb=50)
        chunk_time = time.time() - start_time
        
        total_rows = sum(len(chunk) for chunk in chunks)
        
        print(f"‚è±Ô∏è  –í—Ä–µ–º—è —Å–æ–∑–¥–∞–Ω–∏—è —á–∞–Ω–∫–æ–≤: {chunk_time:.2f} —Å–µ–∫—É–Ω–¥")
        print(f"üìä –°–æ–∑–¥–∞–Ω–æ —á–∞–Ω–∫–æ–≤: {len(chunks)}")
        print(f"üìã –û–±—â–µ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ —Å—Ç—Ä–æ–∫: {total_rows:,}")
        
        # –ê–Ω–∞–ª–∏–∑ —Ä–∞–∑–º–µ—Ä–æ–≤ —á–∞–Ω–∫–æ–≤
        chunk_sizes = [len(chunk) for chunk in chunks]
        print(f"üìè –†–∞–∑–º–µ—Ä—ã —á–∞–Ω–∫–æ–≤: min={min(chunk_sizes):,}, max={max(chunk_sizes):,}, avg={sum(chunk_sizes)/len(chunk_sizes):.0f}")
        
        return {
            'success': True,
            'chunk_time': chunk_time,
            'chunks_count': len(chunks),
            'total_rows': total_rows,
            'chunk_sizes': chunk_sizes
        }
        
    except Exception as e:
        print(f"‚ùå –û—à–∏–±–∫–∞ —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏—è chunk managers: {e}")
        return {'success': False, 'error': str(e)}


def generate_performance_report(seq_results, par_results, chunk_results, test_file: Path):
    """–ì–µ–Ω–µ—Ä–∏—Ä—É–µ—Ç –∏—Ç–æ–≥–æ–≤—ã–π –æ—Ç—á–µ—Ç –æ –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏."""
    print("\nüìä –ò–¢–û–ì–û–í–´–ô –û–¢–ß–ï–¢ –ü–†–û–ò–ó–í–û–î–ò–¢–ï–õ–¨–ù–û–°–¢–ò")
    print("=" * 70)
    
    file_size_mb = test_file.stat().st_size / 1024 / 1024
    print(f"üìÅ –§–∞–π–ª: {test_file.name} ({file_size_mb:.1f}MB)")
    
    if seq_results.get('success') and par_results.get('success'):
        seq_time = seq_results['total_time']
        par_time = par_results['total_time']
        speedup = seq_time / par_time if par_time > 0 else 0
        
        print("\n‚è±Ô∏è  –í–†–ï–ú–Ø –í–´–ü–û–õ–ù–ï–ù–ò–Ø:")
        print(f"   –ü–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–æ: {seq_time:.2f} —Å–µ–∫—É–Ω–¥")
        print(f"   –ü–∞—Ä–∞–ª–ª–µ–ª—å–Ω–æ:     {par_time:.2f} —Å–µ–∫—É–Ω–¥")
        print(f"   –£—Å–∫–æ—Ä–µ–Ω–∏–µ:       {speedup:.2f}x")
        
        print("\n‚ö° –ü–†–û–ò–ó–í–û–î–ò–¢–ï–õ–¨–ù–û–°–¢–¨:")
        print(f"   –ü–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–æ: {seq_results.get('speed', 0):.0f} –∑–∞–ø–∏—Å–µ–π/—Å–µ–∫")
        print(f"   –ü–∞—Ä–∞–ª–ª–µ–ª—å–Ω–æ:     {par_results.get('speed', 0):.0f} –∑–∞–ø–∏—Å–µ–π/—Å–µ–∫")
        
        efficiency = "–í—ã—Å–æ–∫–∞—è" if speedup > 3 else "–°—Ä–µ–¥–Ω—è—è" if speedup > 1.5 else "–ù–∏–∑–∫–∞—è"
        print(f"\nüìà –≠–§–§–ï–ö–¢–ò–í–ù–û–°–¢–¨: {efficiency}")
        
        if speedup > 1:
            time_saved = seq_time - par_time
            print(f"üí∞ –≠–ö–û–ù–û–ú–ò–Ø –í–†–ï–ú–ï–ù–ò: {time_saved:.2f} —Å–µ–∫—É–Ω–¥ ({(time_saved/seq_time*100):.1f}%)")
    
    if chunk_results.get('success'):
        print("\nüîß CHUNK MANAGEMENT:")
        print(f"   –í—Ä–µ–º—è —Å–æ–∑–¥–∞–Ω–∏—è —á–∞–Ω–∫–æ–≤: {chunk_results['chunk_time']:.2f} —Å–µ–∫")
        print(f"   –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ —á–∞–Ω–∫–æ–≤:     {chunk_results['chunks_count']}")
        print(f"   –°—Ä–µ–¥–Ω–∏–π —Ä–∞–∑–º–µ—Ä —á–∞–Ω–∫–∞:  {chunk_results['total_rows']/chunk_results['chunks_count']:.0f} —Å—Ç—Ä–æ–∫")


def export_detailed_report(par_results, output_path: str = "performance_report.html"):
    """–≠–∫—Å–ø–æ—Ä—Ç–∏—Ä—É–µ—Ç –¥–µ—Ç–∞–ª—å–Ω—ã–π –æ—Ç—á–µ—Ç –≤ HTML."""
    if par_results.get('success') and 'results' in par_results:
        try:
            from genoscope.parallel import PerformanceMonitor
            
            # –°–æ–∑–¥–∞–µ–º mock monitor –¥–ª—è –¥–µ–º–æ–Ω—Å—Ç—Ä–∞—Ü–∏–∏
            monitor = PerformanceMonitor()
            results = par_results['results']
            
            if 'performance' in results:
                # –°–æ–∑–¥–∞–µ–º HTML –æ—Ç—á–µ—Ç
                html_content = f"""
<!DOCTYPE html>
<html>
<head>
    <title>BioForge Parallel Processing Report</title>
    <style>
        body {{ font-family: Arial, sans-serif; margin: 20px; }}
        .header {{ background: #667eea; color: white; padding: 20px; border-radius: 8px; }}
        .metric {{ margin: 10px 0; padding: 10px; background: #f8f9fa; border-left: 4px solid #667eea; }}
    </style>
</head>
<body>
    <div class="header">
        <h1>üß¨ BioForge Parallel Processing Report</h1>
        <p>Generated on {time.strftime('%Y-%m-%d %H:%M:%S')}</p>
    </div>
    
    <div class="metric">
        <h3>üìä Processing Summary</h3>
        <p>Total Time: {par_results['total_time']:.2f} seconds</p>
        <p>Records Processed: {par_results['records']:,}</p>
        <p>Processing Speed: {par_results['speed']:.0f} records/sec</p>
        <p>Chunks Processed: {par_results['chunks']}</p>
    </div>
</body>
</html>
                """
                
                with open(output_path, 'w', encoding='utf-8') as f:
                    f.write(html_content)
                
                print(f"üìÑ –î–µ—Ç–∞–ª—å–Ω—ã–π –æ—Ç—á–µ—Ç —Å–æ—Ö—Ä–∞–Ω–µ–Ω: {output_path}")
                
        except Exception as e:
            print(f"‚ö†Ô∏è –ù–µ —É–¥–∞–ª–æ—Å—å —Å–æ–∑–¥–∞—Ç—å –¥–µ—Ç–∞–ª—å–Ω—ã–π –æ—Ç—á–µ—Ç: {e}")


def main():
    """–û—Å–Ω–æ–≤–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è –¥–µ–º–æ–Ω—Å—Ç—Ä–∞—Ü–∏–∏."""
    parser = argparse.ArgumentParser(
        description="–î–µ–º–æ–Ω—Å—Ç—Ä–∞—Ü–∏—è –ø–∞—Ä–∞–ª–ª–µ–ª—å–Ω–æ–π –æ–±—Ä–∞–±–æ—Ç–∫–∏ BioForge",
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog="""
–ü—Ä–∏–º–µ—Ä—ã –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è:
  python test_parallel_demo.py                    # –ë–∞–∑–æ–≤—ã–π —Ç–µ—Å—Ç CSV (150MB)
  python test_parallel_demo.py --size 300 --vcf   # VCF —Ç–µ—Å—Ç (300MB)
  python test_parallel_demo.py --workers 16       # 16 –ø–∞—Ä–∞–ª–ª–µ–ª—å–Ω—ã—Ö –≤–æ—Ä–∫–µ—Ä–æ–≤
        """
    )
    
    parser.add_argument("--size", type=int, default=150,
                       help="–†–∞–∑–º–µ—Ä —Ç–µ—Å—Ç–æ–≤–æ–≥–æ —Ñ–∞–π–ª–∞ –≤ MB (–ø–æ —É–º–æ–ª—á–∞–Ω–∏—é: 150)")
    parser.add_argument("--vcf", action="store_true",
                       help="–ò—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å VCF —Ñ–æ—Ä–º–∞—Ç –≤–º–µ—Å—Ç–æ CSV")
    parser.add_argument("--workers", type=int, default=8,
                       help="–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –ø–∞—Ä–∞–ª–ª–µ–ª—å–Ω—ã—Ö –≤–æ—Ä–∫–µ—Ä–æ–≤ (–ø–æ —É–º–æ–ª—á–∞–Ω–∏—é: 8)")
    parser.add_argument("--skip-sequential", action="store_true",
                       help="–ü—Ä–æ–ø—É—Å—Ç–∏—Ç—å –ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–æ–µ —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ")
    parser.add_argument("--output", type=str, default="performance_report.html",
                       help="–§–∞–π–ª –¥–ª—è –¥–µ—Ç–∞–ª—å–Ω–æ–≥–æ –æ—Ç—á–µ—Ç–∞")
    
    args = parser.parse_args()
    
    print("üß¨ BioForge Parallel Processing Demo")
    print("=" * 70)
    
    file_type = "vcf" if args.vcf else "csv"
    
    try:
        # 1. –°–æ–∑–¥–∞–Ω–∏–µ —Ç–µ—Å—Ç–æ–≤—ã—Ö –¥–∞–Ω–Ω—ã—Ö
        test_file = create_test_genomic_data(args.size, file_type)
        
        # 2. –¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ chunk managers
        chunk_results = benchmark_chunk_managers(test_file, file_type)
        
        # 3. –ü–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–∞—è –æ–±—Ä–∞–±–æ—Ç–∫–∞ (–æ–ø—Ü–∏–æ–Ω–∞–ª—å–Ω–æ)
        if not args.skip_sequential:
            seq_results = benchmark_sequential_processing(test_file, file_type)
        else:
            seq_results = {'success': False}
        
        # 4. –ü–∞—Ä–∞–ª–ª–µ–ª—å–Ω–∞—è –æ–±—Ä–∞–±–æ—Ç–∫–∞
        par_results = benchmark_parallel_processing(test_file, file_type, args.workers)
        
        # 5. –ì–µ–Ω–µ—Ä–∞—Ü–∏—è –æ—Ç—á–µ—Ç–∞
        generate_performance_report(seq_results, par_results, chunk_results, test_file)
        
        # 6. –≠–∫—Å–ø–æ—Ä—Ç –¥–µ—Ç–∞–ª—å–Ω–æ–≥–æ –æ—Ç—á–µ—Ç–∞
        export_detailed_report(par_results, args.output)
        
        print("\nüéâ –î–µ–º–æ–Ω—Å—Ç—Ä–∞—Ü–∏—è –∑–∞–≤–µ—Ä—à–µ–Ω–∞!")
        print(f"üìÅ –¢–µ—Å—Ç–æ–≤—ã–π —Ñ–∞–π–ª: {test_file}")
        print(f"üìÑ –û—Ç—á–µ—Ç: {args.output}")
        
        # Cleanup
        cleanup = input("\nüóëÔ∏è  –£–¥–∞–ª–∏—Ç—å —Ç–µ—Å—Ç–æ–≤—ã–π —Ñ–∞–π–ª? (y/n): ").lower().strip()
        if cleanup == 'y':
            test_file.unlink()
            print(f"üóëÔ∏è  –§–∞–π–ª {test_file} —É–¥–∞–ª–µ–Ω")
        
    except KeyboardInterrupt:
        print("\n\n‚ö†Ô∏è  –î–µ–º–æ–Ω—Å—Ç—Ä–∞—Ü–∏—è –ø—Ä–µ—Ä–≤–∞–Ω–∞ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ–º")
    except Exception as e:
        print(f"\n‚ùå –ù–µ–æ–∂–∏–¥–∞–Ω–Ω–∞—è –æ—à–∏–±–∫–∞: {e}")
        import traceback
        traceback.print_exc()
    finally:
        print("\nüëã –î–æ —Å–≤–∏–¥–∞–Ω–∏—è!")


if __name__ == "__main__":
    main()
