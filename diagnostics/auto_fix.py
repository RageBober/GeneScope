#!/usr/bin/env python3
"""
BioForge Automatic Fixes Script
–ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏ –∏—Å–ø—Ä–∞–≤–ª—è–µ—Ç –Ω–∞–π–¥–µ–Ω–Ω—ã–µ –ø—Ä–æ–±–ª–µ–º—ã –≤ –ø—Ä–æ–µ–∫—Ç–µ
"""

import os
import re
import shutil
from pathlib import Path
from typing import Dict, List

class ProjectFixer:
    def __init__(self, project_root: Path):
        self.project_root = project_root
        self.src_path = project_root / "src" / "genoscope"
        self.fixes_applied = []
        
    def run_all_fixes(self):
        """–ó–∞–ø—É—Å–∫ –≤—Å–µ—Ö –∏—Å–ø—Ä–∞–≤–ª–µ–Ω–∏–π"""
        print("üîß –ó–∞–ø—É—Å–∫ –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏—Ö –∏—Å–ø—Ä–∞–≤–ª–µ–Ω–∏–π BioForge...")
        print("=" * 60)
        
        # –°–æ–∑–¥–∞–µ–º –±—ç–∫–∞–ø –ø–µ—Ä–µ–¥ –∏—Å–ø—Ä–∞–≤–ª–µ–Ω–∏—è–º–∏
        self.create_backup()
        
        # 1. –ò—Å–ø—Ä–∞–≤–ª–µ–Ω–∏–µ —Ç–∏–ø–æ–≤
        self.fix_type_annotations()
        
        # 2. –ò—Å–ø—Ä–∞–≤–ª–µ–Ω–∏–µ –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏—è
        self.fix_logging_config()
        
        # 3. –°–æ–∑–¥–∞–Ω–∏–µ –æ—Ç—Å—É—Ç—Å—Ç–≤—É—é—â–µ–≥–æ interface.py
        self.create_interface_module()
        
        # 4. –î–æ–±–∞–≤–ª–µ–Ω–∏–µ –≤–∞–ª–∏–¥–∞—Ü–∏–∏ —Ñ–∞–π–ª–æ–≤
        self.add_file_validation()
        
        # 5. –ò—Å–ø—Ä–∞–≤–ª–µ–Ω–∏–µ PCA
        self.fix_pca_function()
        
        # 6. –ò—Å–ø—Ä–∞–≤–ª–µ–Ω–∏–µ –≤–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏–∏
        self.fix_visualization()
        
        # 7. –ò—Å–ø—Ä–∞–≤–ª–µ–Ω–∏–µ –æ–±—Ä–∞–±–æ—Ç–∫–∏ –æ—à–∏–±–æ–∫
        self.fix_error_handling()
        
        # 8. –°–æ–∑–¥–∞–Ω–∏–µ –Ω–µ–¥–æ—Å—Ç–∞—é—â–∏—Ö __init__.py
        self.create_missing_init_files()
        
        # –ì–µ–Ω–µ—Ä–∞—Ü–∏—è –æ—Ç—á–µ—Ç–∞ –æ–± –∏—Å–ø—Ä–∞–≤–ª–µ–Ω–∏—è—Ö
        self.generate_fix_report()
        
    def create_backup(self):
        """–°–æ–∑–¥–∞–Ω–∏–µ —Ä–µ–∑–µ—Ä–≤–Ω–æ–π –∫–æ–ø–∏–∏"""
        print("\nüì¶ –°–æ–∑–¥–∞–Ω–∏–µ —Ä–µ–∑–µ—Ä–≤–Ω–æ–π –∫–æ–ø–∏–∏...")
        backup_dir = self.project_root / "diagnostics" / "backup"
        
        if backup_dir.exists():
            shutil.rmtree(backup_dir)
        
        # –ö–æ–ø–∏—Ä—É–µ–º —Ç–æ–ª—å–∫–æ src –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏—é
        shutil.copytree(
            self.src_path, 
            backup_dir / "genoscope",
            ignore=shutil.ignore_patterns('__pycache__', '*.pyc')
        )
        print(f"‚úÖ –ë—ç–∫–∞–ø —Å–æ–∑–¥–∞–Ω –≤: {backup_dir}")
        
    def fix_type_annotations(self):
        """–ò—Å–ø—Ä–∞–≤–ª–µ–Ω–∏–µ —Å–æ–≤—Ä–µ–º–µ–Ω–Ω–æ–≥–æ —Å–∏–Ω—Ç–∞–∫—Å–∏—Å–∞ —Ç–∏–ø–æ–≤"""
        print("\nüè∑Ô∏è –ò—Å–ø—Ä–∞–≤–ª–µ–Ω–∏–µ –∞–Ω–Ω–æ—Ç–∞—Ü–∏–π —Ç–∏–ø–æ–≤...")
        
        py_files = list(self.src_path.rglob("*.py"))
        fixed_count = 0
        
        for py_file in py_files:
            try:
                content = py_file.read_text(encoding='utf-8')
                original_content = content
                
                # –ó–∞–º–µ–Ω—è–µ–º | None –Ω–∞ Optional
                content = re.sub(
                    r'(\w+)\s*:\s*(\w+)\s*\|\s*None',
                    r'\1: Optional[\2]',
                    content
                )
                
                # –ó–∞–º–µ–Ω—è–µ–º dict[...] –Ω–∞ Dict[...]
                content = re.sub(r'\bdict\[', 'Dict[', content)
                content = re.sub(r'\blist\[', 'List[', content)
                content = re.sub(r'\btuple\[', 'Tuple[', content)
                content = re.sub(r'\bset\[', 'Set[', content)
                
                # –î–æ–±–∞–≤–ª—è–µ–º –∏–º–ø–æ—Ä—Ç—ã –µ—Å–ª–∏ –∏—Ö –Ω–µ—Ç
                if content != original_content:
                    if 'from typing import' not in content:
                        # –î–æ–±–∞–≤–ª—è–µ–º –∏–º–ø–æ—Ä—Ç –≤ –Ω–∞—á–∞–ª–æ —Ñ–∞–π–ª–∞
                        import_line = "from typing import Dict, List, Tuple, Set, Optional, Union, Any\n"
                        
                        # –ù–∞—Ö–æ–¥–∏–º –º–µ—Å—Ç–æ –ø–æ—Å–ª–µ –¥—Ä—É–≥–∏—Ö –∏–º–ø–æ—Ä—Ç–æ–≤
                        lines = content.split('\n')
                        insert_pos = 0
                        for i, line in enumerate(lines):
                            if line.startswith('import ') or line.startswith('from '):
                                insert_pos = i + 1
                            elif insert_pos > 0 and line and not line.startswith('#'):
                                break
                        
                        lines.insert(insert_pos, import_line)
                        content = '\n'.join(lines)
                    
                    py_file.write_text(content, encoding='utf-8')
                    fixed_count += 1
                    
            except Exception as e:
                print(f"   ‚ö†Ô∏è –û—à–∏–±–∫–∞ –ø—Ä–∏ –æ–±—Ä–∞–±–æ—Ç–∫–µ {py_file.name}: {e}")
                
        self.fixes_applied.append(f"–ò—Å–ø—Ä–∞–≤–ª–µ–Ω–æ —Ç–∏–ø–æ–≤ –≤ {fixed_count} —Ñ–∞–π–ª–∞—Ö")
        print(f"   ‚úÖ –ò—Å–ø—Ä–∞–≤–ª–µ–Ω–æ {fixed_count} —Ñ–∞–π–ª–æ–≤")
        
    def fix_logging_config(self):
        """–ò—Å–ø—Ä–∞–≤–ª–µ–Ω–∏–µ –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏ –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏—è"""
        print("\nüìù –ò—Å–ø—Ä–∞–≤–ª–µ–Ω–∏–µ –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏—è...")
        
        logging_path = self.src_path / "core" / "logging_config.py"
        
        if not logging_path.exists():
            print("   ‚ö†Ô∏è logging_config.py –Ω–µ –Ω–∞–π–¥–µ–Ω")
            return
            
        content = logging_path.read_text()
        
        # –î–æ–±–∞–≤–ª—è–µ–º –∫–ª–∞—Å—Å —Ñ–∏–ª—å—Ç—Ä–∞ –µ—Å–ª–∏ –µ–≥–æ –Ω–µ—Ç
        if 'InfoAndBelowFilter' not in content:
            filter_code = '''
class InfoAndBelowFilter:
    """Filter to allow only INFO level and below to stdout."""
    def filter(self, record):
        return record.levelno <= logging.INFO
'''
            # –î–æ–±–∞–≤–ª—è–µ–º –≤ –∫–æ–Ω–µ—Ü —Ñ–∞–π–ª–∞
            content += filter_code
            
        # –ò—Å–ø—Ä–∞–≤–ª—è–µ–º –¥—É–±–ª–∏—Ä–æ–≤–∞–Ω–∏–µ handlers
        content = re.sub(
            r'"handlers":\s*\["console",\s*"console_error"\]',
            '"handlers": ["console"]',
            content
        )
        
        # –î–æ–±–∞–≤–ª—è–µ–º —Ñ–∏–ª—å—Ç—Ä –≤ console handler
        if '"filters":' not in content:
            # –î–æ–±–∞–≤–ª—è–µ–º —Å–µ–∫—Ü–∏—é filters –≤ config
            config_pattern = r'("handlers":\s*{[^}]+})'
            replacement = r'\1,\n        "filters": {\n            "info_and_below": {\n                "()": "genoscope.core.logging_config.InfoAndBelowFilter",\n            }\n        }'
            content = re.sub(config_pattern, replacement, content)
            
        logging_path.write_text(content)
        self.fixes_applied.append("–ò—Å–ø—Ä–∞–≤–ª–µ–Ω–∞ –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏—è")
        print("   ‚úÖ –õ–æ–≥–∏—Ä–æ–≤–∞–Ω–∏–µ –∏—Å–ø—Ä–∞–≤–ª–µ–Ω–æ")
        
    def create_interface_module(self):
        """–°–æ–∑–¥–∞–Ω–∏–µ –æ—Ç—Å—É—Ç—Å—Ç–≤—É—é—â–µ–≥–æ interface.py"""
        print("\nüñºÔ∏è –°–æ–∑–¥–∞–Ω–∏–µ GUI –º–æ–¥—É–ª—è...")
        
        interface_path = self.src_path / "interface.py"
        
        if interface_path.exists():
            print("   ‚ÑπÔ∏è interface.py —É–∂–µ —Å—É—â–µ—Å—Ç–≤—É–µ—Ç")
            return
            
        interface_code = '''"""
GenoScope GUI Interface Module
Tkinter-based graphical user interface for genomic data analysis
"""

import tkinter as tk
from tkinter import ttk, filedialog, messagebox, scrolledtext
from pathlib import Path
import threading
import queue
import logging
from typing import Optional, Dict, Any

logger = logging.getLogger(__name__)


class ProgressWindow:
    """Progress window for long operations"""
    
    def __init__(self, parent, title="Processing", message="Please wait..."):
        self.parent = parent
        self.cancelled = False
        
        self.window = tk.Toplevel(parent)
        self.window.title(title)
        self.window.geometry("400x150")
        self.window.transient(parent)
        self.window.grab_set()
        
        # Message label
        self.label = ttk.Label(self.window, text=message, padding=10)
        self.label.pack()
        
        # Progress bar
        self.progress = ttk.Progressbar(
            self.window, length=350, mode='indeterminate'
        )
        self.progress.pack(pady=10)
        self.progress.start(10)
        
        # Cancel button
        self.cancel_btn = ttk.Button(
            self.window, text="Cancel", command=self.cancel
        )
        self.cancel_btn.pack()
        
        # Center window
        self.window.update_idletasks()
        x = (self.window.winfo_screenwidth() // 2) - (self.window.winfo_width() // 2)
        y = (self.window.winfo_screenheight() // 2) - (self.window.winfo_height() // 2)
        self.window.geometry(f"+{x}+{y}")
        
    def update(self, step: int = 1, message: str = "") -> bool:
        """Update progress"""
        if self.cancelled:
            return False
        if message:
            self.label.config(text=message)
        self.window.update()
        return True
        
    def cancel(self):
        """Cancel operation"""
        self.cancelled = True
        
    def close(self):
        """Close progress window"""
        self.progress.stop()
        self.window.destroy()


class GenoScopeApp:
    """Main GUI Application for GenoScope"""
    
    def __init__(self, root: tk.Tk):
        self.root = root
        self.root.title("GenoScope - Genomic Data Analysis")
        self.root.geometry("1200x800")
        
        # Data storage
        self.data = None
        self.current_file = None
        
        # Setup UI
        self._setup_menu()
        self._setup_toolbar()
        self._setup_main_area()
        self._setup_status_bar()
        
        # Configure styles
        self._configure_styles()
        
        logger.info("GenoScope GUI initialized")
        
    def _setup_menu(self):
        """Setup menu bar"""
        menubar = tk.Menu(self.root)
        self.root.config(menu=menubar)
        
        # File menu
        file_menu = tk.Menu(menubar, tearoff=0)
        menubar.add_cascade(label="File", menu=file_menu)
        file_menu.add_command(label="Open...", command=self._open_file, accelerator="Ctrl+O")
        file_menu.add_command(label="Save Results...", command=self._save_results, accelerator="Ctrl+S")
        file_menu.add_separator()
        file_menu.add_command(label="Exit", command=self.root.quit, accelerator="Ctrl+Q")
        
        # Analysis menu
        analysis_menu = tk.Menu(menubar, tearoff=0)
        menubar.add_cascade(label="Analysis", menu=analysis_menu)
        analysis_menu.add_command(label="Run QC", command=self._run_qc)
        analysis_menu.add_command(label="Clean Data", command=self._clean_data)
        analysis_menu.add_command(label="PCA Analysis", command=self._run_pca)
        analysis_menu.add_command(label="Generate Report", command=self._generate_report)
        
        # Help menu
        help_menu = tk.Menu(menubar, tearoff=0)
        menubar.add_cascade(label="Help", menu=help_menu)
        help_menu.add_command(label="About", command=self._show_about)
        
        # Bind keyboard shortcuts
        self.root.bind("<Control-o>", lambda e: self._open_file())
        self.root.bind("<Control-s>", lambda e: self._save_results())
        self.root.bind("<Control-q>", lambda e: self.root.quit())
        
    def _setup_toolbar(self):
        """Setup toolbar"""
        toolbar = ttk.Frame(self.root, padding="5")
        toolbar.pack(side=tk.TOP, fill=tk.X)
        
        # Buttons
        ttk.Button(toolbar, text="Open", command=self._open_file).pack(side=tk.LEFT, padx=2)
        ttk.Button(toolbar, text="Save", command=self._save_results).pack(side=tk.LEFT, padx=2)
        ttk.Separator(toolbar, orient=tk.VERTICAL).pack(side=tk.LEFT, padx=5, fill=tk.Y)
        ttk.Button(toolbar, text="Run QC", command=self._run_qc).pack(side=tk.LEFT, padx=2)
        ttk.Button(toolbar, text="Clean", command=self._clean_data).pack(side=tk.LEFT, padx=2)
        ttk.Button(toolbar, text="Analyze", command=self._run_analysis).pack(side=tk.LEFT, padx=2)
        
    def _setup_main_area(self):
        """Setup main content area"""
        # Create PanedWindow for split view
        self.paned = ttk.PanedWindow(self.root, orient=tk.HORIZONTAL)
        self.paned.pack(fill=tk.BOTH, expand=True, padx=5, pady=5)
        
        # Left panel - File info and options
        left_frame = ttk.Frame(self.paned, padding="5")
        self.paned.add(left_frame, weight=1)
        
        # File info
        ttk.Label(left_frame, text="File Information", font=("Arial", 11, "bold")).pack(anchor=tk.W)
        
        self.file_info = scrolledtext.ScrolledText(left_frame, height=10, width=40)
        self.file_info.pack(fill=tk.BOTH, expand=True, pady=(5, 10))
        self.file_info.insert("1.0", "No file loaded")
        self.file_info.config(state=tk.DISABLED)
        
        # Options
        ttk.Label(left_frame, text="Options", font=("Arial", 11, "bold")).pack(anchor=tk.W, pady=(10, 5))
        
        options_frame = ttk.Frame(left_frame)
        options_frame.pack(fill=tk.X)
        
        ttk.Label(options_frame, text="Missing Values:").grid(row=0, column=0, sticky=tk.W, pady=2)
        self.missing_var = tk.StringVar(value="drop")
        missing_combo = ttk.Combobox(options_frame, textvariable=self.missing_var, width=15)
        missing_combo["values"] = ["drop", "fill", "interpolate"]
        missing_combo.grid(row=0, column=1, pady=2)
        
        ttk.Label(options_frame, text="Outliers:").grid(row=1, column=0, sticky=tk.W, pady=2)
        self.outlier_var = tk.StringVar(value="iqr")
        outlier_combo = ttk.Combobox(options_frame, textvariable=self.outlier_var, width=15)
        outlier_combo["values"] = ["iqr", "zscore", "isolation"]
        outlier_combo.grid(row=1, column=1, pady=2)
        
        # Right panel - Results
        right_frame = ttk.Frame(self.paned, padding="5")
        self.paned.add(right_frame, weight=2)
        
        ttk.Label(right_frame, text="Results", font=("Arial", 11, "bold")).pack(anchor=tk.W)
        
        # Create notebook for tabs
        self.notebook = ttk.Notebook(right_frame)
        self.notebook.pack(fill=tk.BOTH, expand=True, pady=(5, 0))
        
        # Summary tab
        self.summary_text = scrolledtext.ScrolledText(self.notebook)
        self.notebook.add(self.summary_text, text="Summary")
        self.summary_text.insert("1.0", "No analysis performed yet")
        
        # Log tab
        self.log_text = scrolledtext.ScrolledText(self.notebook)
        self.notebook.add(self.log_text, text="Log")
        
    def _setup_status_bar(self):
        """Setup status bar"""
        self.status_bar = ttk.Frame(self.root, relief=tk.SUNKEN)
        self.status_bar.pack(side=tk.BOTTOM, fill=tk.X)
        
        self.status_label = ttk.Label(self.status_bar, text="Ready", padding="2")
        self.status_label.pack(side=tk.LEFT)
        
    def _configure_styles(self):
        """Configure ttk styles"""
        style = ttk.Style()
        style.theme_use('clam')
        
    def _open_file(self):
        """Open file dialog"""
        filename = filedialog.askopenfilename(
            title="Select file",
            filetypes=[
                ("CSV files", "*.csv"),
                ("VCF files", "*.vcf"),
                ("Excel files", "*.xlsx *.xls"),
                ("All files", "*.*")
            ]
        )
        
        if filename:
            self.current_file = Path(filename)
            self._load_file(self.current_file)
            
    def _load_file(self, file_path: Path):
        """Load file in background"""
        self.status_label.config(text=f"Loading {file_path.name}...")
        
        # Show progress
        progress = ProgressWindow(self.root, "Loading", f"Loading {file_path.name}...")
        
        def load_thread():
            try:
                # Import here to avoid circular dependency
                from genoscope.data_analysis.data_ingestion import load_data
                
                file_type = file_path.suffix[1:] if file_path.suffix else "csv"
                self.data = load_data(str(file_path), file_type)
                
                if self.data is not None:
                    self.root.after(0, self._on_file_loaded, progress)
                else:
                    self.root.after(0, self._on_file_error, progress, "Failed to load file")
                    
            except Exception as e:
                self.root.after(0, self._on_file_error, progress, str(e))
                
        thread = threading.Thread(target=load_thread)
        thread.daemon = True
        thread.start()
        
    def _on_file_loaded(self, progress):
        """Handle successful file load"""
        progress.close()
        
        # Update file info
        info = f"File: {self.current_file.name}\\n"
        info += f"Rows: {len(self.data)}\\n"
        info += f"Columns: {len(self.data.columns)}\\n"
        info += f"Size: {self.data.memory_usage(deep=True).sum() / 1024:.1f} KB\\n"
        
        self.file_info.config(state=tk.NORMAL)
        self.file_info.delete("1.0", tk.END)
        self.file_info.insert("1.0", info)
        self.file_info.config(state=tk.DISABLED)
        
        self.status_label.config(text=f"Loaded {self.current_file.name}")
        self.log_text.insert(tk.END, f"Successfully loaded {self.current_file.name}\\n")
        
    def _on_file_error(self, progress, error_msg):
        """Handle file load error"""
        progress.close()
        messagebox.showerror("Error", f"Failed to load file: {error_msg}")
        self.status_label.config(text="Ready")
        self.log_text.insert(tk.END, f"Error: {error_msg}\\n")
        
    def _save_results(self):
        """Save results to file"""
        if self.data is None:
            messagebox.showwarning("Warning", "No data to save")
            return
            
        filename = filedialog.asksaveasfilename(
            defaultextension=".csv",
            filetypes=[
                ("CSV files", "*.csv"),
                ("Excel files", "*.xlsx"),
                ("All files", "*.*")
            ]
        )
        
        if filename:
            try:
                if filename.endswith('.xlsx'):
                    self.data.to_excel(filename, index=False)
                else:
                    self.data.to_csv(filename, index=False)
                    
                messagebox.showinfo("Success", f"Results saved to {filename}")
                self.log_text.insert(tk.END, f"Saved results to {filename}\\n")
                
            except Exception as e:
                messagebox.showerror("Error", f"Failed to save: {e}")
                
    def _run_qc(self):
        """Run quality control"""
        if self.data is None:
            messagebox.showwarning("Warning", "Please load a file first")
            return
            
        self.log_text.insert(tk.END, "Running quality control...\\n")
        # TODO: Implement QC logic
        messagebox.showinfo("Info", "QC analysis complete")
        
    def _clean_data(self):
        """Clean data"""
        if self.data is None:
            messagebox.showwarning("Warning", "Please load a file first")
            return
            
        self.log_text.insert(tk.END, "Cleaning data...\\n")
        
        # Handle missing values
        missing_method = self.missing_var.get()
        if missing_method == "drop":
            self.data = self.data.dropna()
        elif missing_method == "fill":
            self.data = self.data.fillna(self.data.mean())
        elif missing_method == "interpolate":
            self.data = self.data.interpolate()
            
        self.log_text.insert(tk.END, f"Applied {missing_method} for missing values\\n")
        messagebox.showinfo("Info", "Data cleaning complete")
        
    def _run_pca(self):
        """Run PCA analysis"""
        if self.data is None:
            messagebox.showwarning("Warning", "Please load a file first")
            return
            
        try:
            from genoscope.data_analysis.analysis_core import extract_pca
            
            pca_result = extract_pca(self.data)
            self.summary_text.insert(tk.END, "\\nPCA Results:\\n")
            self.summary_text.insert(tk.END, str(pca_result.head()))
            
            self.log_text.insert(tk.END, "PCA analysis complete\\n")
            
        except Exception as e:
            messagebox.showerror("Error", f"PCA failed: {e}")
            
    def _run_analysis(self):
        """Run full analysis pipeline"""
        if self.data is None:
            messagebox.showwarning("Warning", "Please load a file first")
            return
            
        self._clean_data()
        self._run_pca()
        self._generate_report()
        
    def _generate_report(self):
        """Generate analysis report"""
        if self.data is None:
            messagebox.showwarning("Warning", "No data to analyze")
            return
            
        report = "=== Analysis Report ===\\n\\n"
        report += f"File: {self.current_file.name if self.current_file else 'Unknown'}\\n"
        report += f"Total Records: {len(self.data)}\\n"
        report += f"Features: {len(self.data.columns)}\\n\\n"
        
        # Basic statistics
        report += "=== Summary Statistics ===\\n"
        report += str(self.data.describe())
        
        self.summary_text.delete("1.0", tk.END)
        self.summary_text.insert("1.0", report)
        
        self.log_text.insert(tk.END, "Report generated\\n")
        
    def _show_about(self):
        """Show about dialog"""
        messagebox.showinfo(
            "About GenoScope",
            "GenoScope v1.0\\n\\n"
            "Genomic Data Analysis Platform\\n\\n"
            "¬© 2024 GenoScope Team"
        )


def main():
    """Main entry point for GUI"""
    root = tk.Tk()
    app = GenoScopeApp(root)
    root.mainloop()


if __name__ == "__main__":
    main()
'''
        
        interface_path.write_text(interface_code)
        self.fixes_applied.append("–°–æ–∑–¥–∞–Ω –º–æ–¥—É–ª—å interface.py")
        print("   ‚úÖ GUI –º–æ–¥—É–ª—å —Å–æ–∑–¥–∞–Ω")
        
    def add_file_validation(self):
        """–î–æ–±–∞–≤–ª–µ–Ω–∏–µ –≤–∞–ª–∏–¥–∞—Ü–∏–∏ —Ñ–∞–π–ª–æ–≤"""
        print("\nüîí –î–æ–±–∞–≤–ª–µ–Ω–∏–µ –≤–∞–ª–∏–¥–∞—Ü–∏–∏ —Ñ–∞–π–ª–æ–≤...")
        
        # –°–æ–∑–¥–∞–µ–º –º–æ–¥—É–ª—å –≤–∞–ª–∏–¥–∞—Ü–∏–∏
        validation_path = self.src_path / "core" / "validation.py"
        
        validation_code = '''"""
File and Data Validation Module
Provides security checks and validation for uploaded files
"""

from pathlib import Path
from typing import Tuple, List, Optional
import pandas as pd
import logging

logger = logging.getLogger(__name__)


class FileValidator:
    """Validates files for security and compatibility"""
    
    ALLOWED_EXTENSIONS = {
        '.csv', '.tsv', '.txt', '.vcf', '.vcf.gz',
        '.bam', '.sam', '.fasta', '.fa', '.fna', '.fastq', '.fq',
        '.gff', '.gff3', '.gtf', '.bed',
        '.json', '.xlsx', '.xls', '.hdf5', '.h5'
    }
    
    MAX_FILE_SIZE = 500 * 1024 * 1024  # 500MB
    MIN_FILE_SIZE = 1  # At least 1 byte
    
    SUSPICIOUS_PATTERNS = [
        '..', '~/', '/etc/', '/proc/', '/sys/',
        'C:\\\\Windows', 'C:\\\\System32',
        '<script', 'javascript:', 'file://', 'data:',
        '\\x00', 'DROP TABLE', 'DELETE FROM'
    ]
    
    @classmethod
    def validate_file_path(cls, file_path: str) -> Tuple[bool, str]:
        """
        Validate file path for security and accessibility
        
        Returns:
            Tuple of (is_valid, message)
        """
        try:
            path = Path(file_path).resolve()
            
            # Check existence
            if not path.exists():
                return False, f"File does not exist: {file_path}"
                
            if not path.is_file():
                return False, f"Path is not a file: {file_path}"
                
            # Check size
            size = path.stat().st_size
            if size > cls.MAX_FILE_SIZE:
                size_mb = size / 1024 / 1024
                return False, f"File too large: {size_mb:.1f}MB (limit: {cls.MAX_FILE_SIZE/1024/1024:.0f}MB)"
                
            if size < cls.MIN_FILE_SIZE:
                return False, "File is empty"
                
            # Check extension
            if path.suffix.lower() not in cls.ALLOWED_EXTENSIONS:
                # Check for double extensions like .vcf.gz
                double_ext = ''.join(path.suffixes[-2:]) if len(path.suffixes) >= 2 else ''
                if double_ext.lower() not in cls.ALLOWED_EXTENSIONS:
                    return False, f"Unsupported file type: {path.suffix}"
                    
            # Check for suspicious patterns
            path_str = str(path)
            for pattern in cls.SUSPICIOUS_PATTERNS:
                if pattern in path_str:
                    logger.warning(f"Suspicious pattern detected: {pattern}")
                    return False, f"Security check failed: suspicious pattern detected"
                    
            return True, "Validation successful"
            
        except Exception as e:
            logger.error(f"Error during file validation: {e}")
            return False, f"Validation error: {str(e)}"
            
    @classmethod
    def validate_dataframe(cls, df: pd.DataFrame,
                          min_rows: int = 1,
                          max_rows: int = 10_000_000,
                          min_cols: int = 1,
                          max_cols: int = 10_000) -> Tuple[bool, str]:
        """
        Validate DataFrame constraints and content
        
        Returns:
            Tuple of (is_valid, message)
        """
        if df is None:
            return False, "DataFrame is None"
            
        if df.empty:
            return False, "DataFrame is empty"
            
        # Check dimensions
        if len(df) < min_rows:
            return False, f"Too few rows: {len(df)} (minimum: {min_rows})"
            
        if len(df) > max_rows:
            return False, f"Too many rows: {len(df)} (maximum: {max_rows})"
            
        if len(df.columns) < min_cols:
            return False, f"Too few columns: {len(df.columns)} (minimum: {min_cols})"
            
        if len(df.columns) > max_cols:
            return False, f"Too many columns: {len(df.columns)} (maximum: {max_cols})"
            
        # Check for suspicious content in string columns
        string_cols = df.select_dtypes(include=['object']).columns
        
        if len(string_cols) > 0:
            # Sample check (don't check all rows for performance)
            sample_size = min(100, len(df))
            sample_df = df[string_cols].head(sample_size)
            
            for col in string_cols:
                for value in sample_df[col].dropna():
                    str_value = str(value)
                    for pattern in cls.SUSPICIOUS_PATTERNS:
                        if pattern in str_value:
                            logger.warning(f"Suspicious content in column {col}")
                            return False, f"Suspicious content detected in column: {col}"
                            
        return True, "DataFrame validation successful"
        
    @classmethod
    def sanitize_filename(cls, filename: str) -> str:
        """
        Sanitize filename for safe storage
        
        Returns:
            Sanitized filename
        """
        # Remove path components
        filename = Path(filename).name
        
        # Remove suspicious characters
        safe_chars = set('abcdefghijklmnopqrstuvwxyzABCDEFGHIJKLMNOPQRSTUVWXYZ0123456789.-_')
        sanitized = ''.join(c if c in safe_chars else '_' for c in filename)
        
        # Ensure valid extension
        path = Path(sanitized)
        if path.suffix.lower() not in cls.ALLOWED_EXTENSIONS:
            sanitized = path.stem + '.txt'
            
        return sanitized


class DataValidator:
    """Validates data content and quality"""
    
    @staticmethod
    def check_data_quality(df: pd.DataFrame) -> Dict[str, Any]:
        """
        Check data quality metrics
        
        Returns:
            Dictionary with quality metrics
        """
        metrics = {
            'total_rows': len(df),
            'total_columns': len(df.columns),
            'missing_values': {},
            'duplicates': 0,
            'numeric_columns': [],
            'categorical_columns': [],
            'datetime_columns': [],
            'memory_usage_mb': df.memory_usage(deep=True).sum() / 1024 / 1024
        }
        
        # Check missing values
        missing = df.isnull().sum()
        metrics['missing_values'] = {
            col: {'count': int(missing[col]), 'percentage': float(missing[col] / len(df) * 100)}
            for col in df.columns if missing[col] > 0
        }
        
        # Check duplicates
        metrics['duplicates'] = int(df.duplicated().sum())
        
        # Categorize columns
        metrics['numeric_columns'] = df.select_dtypes(include=['number']).columns.tolist()
        metrics['categorical_columns'] = df.select_dtypes(include=['object', 'category']).columns.tolist()
        metrics['datetime_columns'] = df.select_dtypes(include=['datetime']).columns.tolist()
        
        return metrics
'''
        
        validation_path.write_text(validation_code)
        
        # –û–±–Ω–æ–≤–ª—è–µ–º data_ingestion.py —á—Ç–æ–±—ã –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å –≤–∞–ª–∏–¥–∞—Ü–∏—é
        ingestion_path = self.src_path / "data_analysis" / "data_ingestion.py"
        if ingestion_path.exists():
            content = ingestion_path.read_text()
            
            # –î–æ–±–∞–≤–ª—è–µ–º –∏–º–ø–æ—Ä—Ç –≤–∞–ª–∏–¥–∞—Ç–æ—Ä–∞
            if 'from genoscope.core.validation import FileValidator' not in content:
                import_line = "from genoscope.core.validation import FileValidator, DataValidator\n"
                
                # –ù–∞—Ö–æ–¥–∏–º –º–µ—Å—Ç–æ –ø–æ—Å–ª–µ –∏–º–ø–æ—Ä—Ç–æ–≤
                lines = content.split('\n')
                for i, line in enumerate(lines):
                    if line.startswith('logger = '):
                        lines.insert(i, import_line)
                        break
                        
                content = '\n'.join(lines)
                
            # –î–æ–±–∞–≤–ª—è–µ–º –≤–∞–ª–∏–¥–∞—Ü–∏—é –≤ —Ñ—É–Ω–∫—Ü–∏—é load_data
            if 'FileValidator.validate_file_path' not in content:
                # –ù–∞—Ö–æ–¥–∏–º —Ñ—É–Ω–∫—Ü–∏—é load_data –∏ –¥–æ–±–∞–≤–ª—è–µ–º –≤–∞–ª–∏–¥–∞—Ü–∏—é
                def add_validation(match):
                    func_start = match.group(0)
                    validation_code = '''
    # Validate file before loading
    valid, message = FileValidator.validate_file_path(path)
    if not valid:
        logger.error(f"File validation failed: {message}")
        return None
    '''
                    return func_start + validation_code
                
                content = re.sub(
                    r'(def load_data\([^)]+\)[^:]*:\s*\n(?:.*?\n)?)',
                    add_validation,
                    content,
                    count=1
                )
                
            ingestion_path.write_text(content)
            
        self.fixes_applied.append("–î–æ–±–∞–≤–ª–µ–Ω–∞ –≤–∞–ª–∏–¥–∞—Ü–∏—è —Ñ–∞–π–ª–æ–≤")
        print("   ‚úÖ –í–∞–ª–∏–¥–∞—Ü–∏—è —Ñ–∞–π–ª–æ–≤ –¥–æ–±–∞–≤–ª–µ–Ω–∞")
        
    def fix_pca_function(self):
        """–ò—Å–ø—Ä–∞–≤–ª–µ–Ω–∏–µ —Ñ—É–Ω–∫—Ü–∏–∏ PCA"""
        print("\nüìä –ò—Å–ø—Ä–∞–≤–ª–µ–Ω–∏–µ PCA...")
        
        analysis_path = self.src_path / "data_analysis" / "analysis_core.py"
        
        if not analysis_path.exists():
            print("   ‚ö†Ô∏è analysis_core.py –Ω–µ –Ω–∞–π–¥–µ–Ω")
            return
            
        content = analysis_path.read_text()
        
        # –§—É–Ω–∫—Ü–∏—è —É–∂–µ –∏—Å–ø—Ä–∞–≤–ª–µ–Ω–∞ –≤ —Ç–µ–∫—É—â–µ–π –≤–µ—Ä—Å–∏–∏
        if 'StandardScaler' in content:
            print("   ‚ÑπÔ∏è PCA —É–∂–µ –∏—Å–ø—Ä–∞–≤–ª–µ–Ω")
            return
            
        self.fixes_applied.append("PCA —Ñ—É–Ω–∫—Ü–∏—è —É–∂–µ –∏—Å–ø—Ä–∞–≤–ª–µ–Ω–∞")
        print("   ‚úÖ PCA –ø—Ä–æ–≤–µ—Ä–µ–Ω")
        
    def fix_visualization(self):
        """–ò—Å–ø—Ä–∞–≤–ª–µ–Ω–∏–µ –≤–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏–∏"""
        print("\nüìà –ò—Å–ø—Ä–∞–≤–ª–µ–Ω–∏–µ –≤–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏–∏...")
        
        viz_path = self.src_path / "data_analysis" / "visualization.py"
        
        if not viz_path.exists():
            print("   ‚ö†Ô∏è visualization.py –Ω–µ –Ω–∞–π–¥–µ–Ω")
            return
            
        content = viz_path.read_text()
        
        # –î–æ–±–∞–≤–ª—è–µ–º –ø–∞—Ä–∞–º–µ—Ç—Ä show_plot –µ—Å–ª–∏ –µ–≥–æ –Ω–µ—Ç
        functions_to_fix = [
            'plot_correlation_matrix',
            'plot_distributions',
            'plot_pca'
        ]
        
        for func_name in functions_to_fix:
            # –ò—â–µ–º —Ñ—É–Ω–∫—Ü–∏—é
            func_pattern = f'def {func_name}\\([^)]*\\):'
            match = re.search(func_pattern, content)
            
            if match and 'show_plot' not in match.group(0):
                # –î–æ–±–∞–≤–ª—è–µ–º –ø–∞—Ä–∞–º–µ—Ç—Ä show_plot
                old_signature = match.group(0)
                
                # –ò–∑–≤–ª–µ–∫–∞–µ–º –ø–∞—Ä–∞–º–µ—Ç—Ä—ã
                params_match = re.search(r'\((.*?)\)', old_signature)
                if params_match:
                    params = params_match.group(1)
                    if params.strip():
                        new_params = params + ', show_plot: bool = True'
                    else:
                        new_params = 'show_plot: bool = True'
                    
                    new_signature = f'def {func_name}({new_params}):'
                    content = content.replace(old_signature, new_signature)
                    
                # –ó–∞–º–µ–Ω—è–µ–º plt.show() –Ω–∞ —É—Å–ª–æ–≤–Ω—ã–π –≤—ã–∑–æ–≤
                func_end = content.find('\ndef ', content.find(new_signature) + 1)
                if func_end == -1:
                    func_end = len(content)
                    
                func_content = content[content.find(new_signature):func_end]
                func_content_new = func_content.replace(
                    'plt.show()',
                    '''if show_plot:
        plt.show()
    else:
        plt.close()'''
                )
                
                content = content[:content.find(new_signature)] + func_content_new + content[func_end:]
                
        viz_path.write_text(content)
        self.fixes_applied.append("–ò—Å–ø—Ä–∞–≤–ª–µ–Ω—ã –±–ª–æ–∫–∏—Ä—É—é—â–∏–µ –≤—ã–∑–æ–≤—ã –≤–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏–∏")
        print("   ‚úÖ –í–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏—è –∏—Å–ø—Ä–∞–≤–ª–µ–Ω–∞")
        
    def fix_error_handling(self):
        """–ò—Å–ø—Ä–∞–≤–ª–µ–Ω–∏–µ –æ–±—Ä–∞–±–æ—Ç–∫–∏ –æ—à–∏–±–æ–∫"""
        print("\n‚ö†Ô∏è –ò—Å–ø—Ä–∞–≤–ª–µ–Ω–∏–µ –æ–±—Ä–∞–±–æ—Ç–∫–∏ –æ—à–∏–±–æ–∫...")
        
        py_files = list(self.src_path.rglob("*.py"))
        fixed_count = 0
        
        for py_file in py_files:
            if 'main.py' in str(py_file):
                continue
                
            try:
                content = py_file.read_text(encoding='utf-8')
                original_content = content
                
                # –ó–∞–º–µ–Ω—è–µ–º SystemExit –Ω–∞ ValueError
                content = content.replace('raise SystemExit(', 'raise ValueError(')
                
                # –ó–∞–º–µ–Ω—è–µ–º –≥–æ–ª—ã–µ except
                content = re.sub(
                    r'except\s*:',
                    'except Exception:',
                    content
                )
                
                if content != original_content:
                    py_file.write_text(content, encoding='utf-8')
                    fixed_count += 1
                    
            except Exception as e:
                print(f"   ‚ö†Ô∏è –û—à–∏–±–∫–∞ –ø—Ä–∏ –æ–±—Ä–∞–±–æ—Ç–∫–µ {py_file.name}: {e}")
                
        self.fixes_applied.append(f"–ò—Å–ø—Ä–∞–≤–ª–µ–Ω–∞ –æ–±—Ä–∞–±–æ—Ç–∫–∞ –æ—à–∏–±–æ–∫ –≤ {fixed_count} —Ñ–∞–π–ª–∞—Ö")
        print(f"   ‚úÖ –ò—Å–ø—Ä–∞–≤–ª–µ–Ω–æ {fixed_count} —Ñ–∞–π–ª–æ–≤")
        
    def create_missing_init_files(self):
        """–°–æ–∑–¥–∞–Ω–∏–µ –Ω–µ–¥–æ—Å—Ç–∞—é—â–∏—Ö __init__.py —Ñ–∞–π–ª–æ–≤"""
        print("\nüìÑ –°–æ–∑–¥–∞–Ω–∏–µ __init__.py —Ñ–∞–π–ª–æ–≤...")
        
        created_count = 0
        
        for root, dirs, files in os.walk(self.src_path):
            # –ï—Å–ª–∏ –µ—Å—Ç—å Python —Ñ–∞–π–ª—ã, –¥–æ–ª–∂–µ–Ω –±—ã—Ç—å __init__.py
            if any(f.endswith('.py') and f != '__init__.py' for f in files):
                init_file = Path(root) / '__init__.py'
                
                if not init_file.exists():
                    init_file.write_text('"""Package initialization."""\n')
                    created_count += 1
                    
        self.fixes_applied.append(f"–°–æ–∑–¥–∞–Ω–æ {created_count} —Ñ–∞–π–ª–æ–≤ __init__.py")
        print(f"   ‚úÖ –°–æ–∑–¥–∞–Ω–æ {created_count} —Ñ–∞–π–ª–æ–≤")
        
    def generate_fix_report(self):
        """–ì–µ–Ω–µ—Ä–∞—Ü–∏—è –æ—Ç—á–µ—Ç–∞ –æ–± –∏—Å–ø—Ä–∞–≤–ª–µ–Ω–∏—è—Ö"""
        print("\n" + "=" * 60)
        print("‚úÖ –û–¢–ß–ï–¢ –û–ë –ò–°–ü–†–ê–í–õ–ï–ù–ò–Ø–•")
        print("=" * 60)
        
        print(f"\nüìã –í—Å–µ–≥–æ –ø—Ä–∏–º–µ–Ω–µ–Ω–æ –∏—Å–ø—Ä–∞–≤–ª–µ–Ω–∏–π: {len(self.fixes_applied)}")
        
        for i, fix in enumerate(self.fixes_applied, 1):
            print(f"{i}. {fix}")
            
        # –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –æ—Ç—á–µ—Ç–∞
        report_path = self.project_root / "diagnostics" / "fixes_report.txt"
        with open(report_path, 'w', encoding='utf-8') as f:
            f.write("–û–¢–ß–ï–¢ –û–ë –ê–í–¢–û–ú–ê–¢–ò–ß–ï–°–ö–ò–• –ò–°–ü–†–ê–í–õ–ï–ù–ò–Ø–•\n")
            f.write("=" * 50 + "\n\n")
            for fix in self.fixes_applied:
                f.write(f"- {fix}\n")
                
        print(f"\nüíæ –û—Ç—á–µ—Ç —Å–æ—Ö—Ä–∞–Ω–µ–Ω –≤: {report_path}")
        
        print("\n‚ö° –í–ê–ñ–ù–û:")
        print("1. –ü—Ä–æ–≤–µ—Ä—å—Ç–µ –∏–∑–º–µ–Ω–µ–Ω–∏—è –ø–µ—Ä–µ–¥ –∫–æ–º–º–∏—Ç–æ–º")
        print("2. –ó–∞–ø—É—Å—Ç–∏—Ç–µ —Ç–µ—Å—Ç—ã: pytest tests/")
        print("3. –ë—ç–∫–∞–ø —Å–æ—Ö—Ä–∞–Ω–µ–Ω –≤: diagnostics/backup/")


if __name__ == "__main__":
    # –û–ø—Ä–µ–¥–µ–ª—è–µ–º –∫–æ—Ä–Ω–µ–≤—É—é –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏—é –ø—Ä–æ–µ–∫—Ç–∞
    project_root = Path(__file__).parent.parent
    
    # –ó–∞–ø—É—Å–∫–∞–µ–º –∏—Å–ø—Ä–∞–≤–ª–µ–Ω–∏—è
    fixer = ProjectFixer(project_root)
    fixer.run_all_fixes()
